{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from dataset import WeizmannHumanActionVideo\n",
    "from image_autoencoder import ImageAutoEncoder\n",
    "from lstm_autoencoder import VideoAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trans_data = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\"\"\"\n",
    "\n",
    "trans_data = torchvision.transforms.ToTensor()\n",
    "trans_label = None\n",
    "\n",
    "dataset = WeizmannHumanActionVideo(trans_data=None, trans_label=trans_label, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(1.0 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  93\n",
      "test:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", len(train_dataset))\n",
    "print(\"test: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_loader = torch.utils.data.DataLoader(test_dataset, \\n                                           batch_size=batch_size, \\n                                           shuffle=True, \\n                                           num_workers=1)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4)\n",
    "\n",
    "\"\"\"\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterative algorithm (SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoAutoEncoder(input_size=16, hidden_size=16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_vec.shape:  torch.Size([1, 68, 16])\n",
      "zm:  torch.Size([68, 2]) zc:  torch.Size([68, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 68, 3, 96, 96])) that is different to the input size (torch.Size([68, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 0/93, loss = 0.061691\n",
      "input_vec.shape:  torch.Size([1, 65, 16])\n",
      "zm:  torch.Size([65, 2]) zc:  torch.Size([65, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 65, 3, 96, 96])) that is different to the input size (torch.Size([65, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 1/93, loss = 0.051892\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 57, 3, 96, 96])) that is different to the input size (torch.Size([57, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 2/93, loss = 0.052335\n",
      "input_vec.shape:  torch.Size([1, 49, 16])\n",
      "zm:  torch.Size([49, 2]) zc:  torch.Size([49, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 49, 3, 96, 96])) that is different to the input size (torch.Size([49, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 3/93, loss = 0.037794\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 53, 3, 96, 96])) that is different to the input size (torch.Size([53, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 4/93, loss = 0.031063\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 54, 3, 96, 96])) that is different to the input size (torch.Size([54, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 5/93, loss = 0.039673\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 61, 3, 96, 96])) that is different to the input size (torch.Size([61, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 6/93, loss = 0.030629\n",
      "input_vec.shape:  torch.Size([1, 78, 16])\n",
      "zm:  torch.Size([78, 2]) zc:  torch.Size([78, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 78, 3, 96, 96])) that is different to the input size (torch.Size([78, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 7/93, loss = 0.024891\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 67, 3, 96, 96])) that is different to the input size (torch.Size([67, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 8/93, loss = 0.022346\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 1/10, batch : 9/93, loss = 0.023670\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 56, 3, 96, 96])) that is different to the input size (torch.Size([56, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 10/93, loss = 0.023707\n",
      "input_vec.shape:  torch.Size([1, 73, 16])\n",
      "zm:  torch.Size([73, 2]) zc:  torch.Size([73, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 73, 3, 96, 96])) that is different to the input size (torch.Size([73, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 11/93, loss = 0.022754\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 40, 3, 96, 96])) that is different to the input size (torch.Size([40, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 12/93, loss = 0.019051\n",
      "input_vec.shape:  torch.Size([1, 36, 16])\n",
      "zm:  torch.Size([36, 2]) zc:  torch.Size([36, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 36, 3, 96, 96])) that is different to the input size (torch.Size([36, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 13/93, loss = 0.018483\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 48, 3, 96, 96])) that is different to the input size (torch.Size([48, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 14/93, loss = 0.018535\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 1/10, batch : 15/93, loss = 0.018168\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 52, 3, 96, 96])) that is different to the input size (torch.Size([52, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 16/93, loss = 0.019286\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 51, 3, 96, 96])) that is different to the input size (torch.Size([51, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 17/93, loss = 0.013351\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 72, 3, 96, 96])) that is different to the input size (torch.Size([72, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 18/93, loss = 0.016024\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 62, 3, 96, 96])) that is different to the input size (torch.Size([62, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 19/93, loss = 0.016205\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 42, 3, 96, 96])) that is different to the input size (torch.Size([42, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 20/93, loss = 0.012707\n",
      "input_vec.shape:  torch.Size([1, 36, 16])\n",
      "zm:  torch.Size([36, 2]) zc:  torch.Size([36, 2])\n",
      "epoch : 1/10, batch : 21/93, loss = 0.013432\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n",
      "epoch : 1/10, batch : 22/93, loss = 0.010991\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 1/10, batch : 23/93, loss = 0.010503\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 43, 3, 96, 96])) that is different to the input size (torch.Size([43, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 24/93, loss = 0.011257\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 1/10, batch : 25/93, loss = 0.009426\n",
      "input_vec.shape:  torch.Size([1, 79, 16])\n",
      "zm:  torch.Size([79, 2]) zc:  torch.Size([79, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 79, 3, 96, 96])) that is different to the input size (torch.Size([79, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 26/93, loss = 0.011463\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 1/10, batch : 27/93, loss = 0.009734\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 1/10, batch : 28/93, loss = 0.009656\n",
      "input_vec.shape:  torch.Size([1, 28, 16])\n",
      "zm:  torch.Size([28, 2]) zc:  torch.Size([28, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 28, 3, 96, 96])) that is different to the input size (torch.Size([28, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 29/93, loss = 0.016158\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 60, 3, 96, 96])) that is different to the input size (torch.Size([60, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 30/93, loss = 0.010955\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 39, 3, 96, 96])) that is different to the input size (torch.Size([39, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 31/93, loss = 0.010394\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 1/10, batch : 32/93, loss = 0.009566\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 1/10, batch : 33/93, loss = 0.007513\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 1/10, batch : 34/93, loss = 0.011007\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 1/10, batch : 35/93, loss = 0.014325\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 1/10, batch : 36/93, loss = 0.007760\n",
      "input_vec.shape:  torch.Size([1, 44, 16])\n",
      "zm:  torch.Size([44, 2]) zc:  torch.Size([44, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 44, 3, 96, 96])) that is different to the input size (torch.Size([44, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 37/93, loss = 0.008817\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 41, 3, 96, 96])) that is different to the input size (torch.Size([41, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 38/93, loss = 0.011207\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 45, 3, 96, 96])) that is different to the input size (torch.Size([45, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 39/93, loss = 0.012596\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 1/10, batch : 40/93, loss = 0.010677\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 1/10, batch : 41/93, loss = 0.008469\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 1/10, batch : 42/93, loss = 0.009594\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 1/10, batch : 43/93, loss = 0.007644\n",
      "input_vec.shape:  torch.Size([1, 59, 16])\n",
      "zm:  torch.Size([59, 2]) zc:  torch.Size([59, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 59, 3, 96, 96])) that is different to the input size (torch.Size([59, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 44/93, loss = 0.009128\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 63, 3, 96, 96])) that is different to the input size (torch.Size([63, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 45/93, loss = 0.007187\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 1/10, batch : 46/93, loss = 0.006887\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 1/10, batch : 47/93, loss = 0.006566\n",
      "input_vec.shape:  torch.Size([1, 49, 16])\n",
      "zm:  torch.Size([49, 2]) zc:  torch.Size([49, 2])\n",
      "epoch : 1/10, batch : 48/93, loss = 0.007076\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 1/10, batch : 49/93, loss = 0.009836\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 1/10, batch : 50/93, loss = 0.011414\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 55, 3, 96, 96])) that is different to the input size (torch.Size([55, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 51/93, loss = 0.006343\n",
      "input_vec.shape:  torch.Size([1, 31, 16])\n",
      "zm:  torch.Size([31, 2]) zc:  torch.Size([31, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 31, 3, 96, 96])) that is different to the input size (torch.Size([31, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 52/93, loss = 0.016058\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 1/10, batch : 53/93, loss = 0.007996\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n",
      "epoch : 1/10, batch : 54/93, loss = 0.006356\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 1/10, batch : 55/93, loss = 0.004851\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 1/10, batch : 56/93, loss = 0.006646\n",
      "input_vec.shape:  torch.Size([1, 46, 16])\n",
      "zm:  torch.Size([46, 2]) zc:  torch.Size([46, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 46, 3, 96, 96])) that is different to the input size (torch.Size([46, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 57/93, loss = 0.009529\n",
      "input_vec.shape:  torch.Size([1, 46, 16])\n",
      "zm:  torch.Size([46, 2]) zc:  torch.Size([46, 2])\n",
      "epoch : 1/10, batch : 58/93, loss = 0.005207\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 1/10, batch : 59/93, loss = 0.014235\n",
      "input_vec.shape:  torch.Size([1, 38, 16])\n",
      "zm:  torch.Size([38, 2]) zc:  torch.Size([38, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 38, 3, 96, 96])) that is different to the input size (torch.Size([38, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 60/93, loss = 0.008501\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 1/10, batch : 61/93, loss = 0.006371\n",
      "input_vec.shape:  torch.Size([1, 47, 16])\n",
      "zm:  torch.Size([47, 2]) zc:  torch.Size([47, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 47, 3, 96, 96])) that is different to the input size (torch.Size([47, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 62/93, loss = 0.007809\n",
      "input_vec.shape:  torch.Size([1, 64, 16])\n",
      "zm:  torch.Size([64, 2]) zc:  torch.Size([64, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 64, 3, 96, 96])) that is different to the input size (torch.Size([64, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 63/93, loss = 0.005959\n",
      "input_vec.shape:  torch.Size([1, 70, 16])\n",
      "zm:  torch.Size([70, 2]) zc:  torch.Size([70, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 70, 3, 96, 96])) that is different to the input size (torch.Size([70, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 64/93, loss = 0.005222\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 1/10, batch : 65/93, loss = 0.008535\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 1/10, batch : 66/93, loss = 0.007346\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 1/10, batch : 67/93, loss = 0.011401\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 1/10, batch : 68/93, loss = 0.005404\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 1/10, batch : 69/93, loss = 0.005775\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 1/10, batch : 70/93, loss = 0.004638\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 1/10, batch : 71/93, loss = 0.004478\n",
      "input_vec.shape:  torch.Size([1, 50, 16])\n",
      "zm:  torch.Size([50, 2]) zc:  torch.Size([50, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 50, 3, 96, 96])) that is different to the input size (torch.Size([50, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 72/93, loss = 0.006381\n",
      "input_vec.shape:  torch.Size([1, 73, 16])\n",
      "zm:  torch.Size([73, 2]) zc:  torch.Size([73, 2])\n",
      "epoch : 1/10, batch : 73/93, loss = 0.015451\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 1/10, batch : 74/93, loss = 0.005373\n",
      "input_vec.shape:  torch.Size([1, 37, 16])\n",
      "zm:  torch.Size([37, 2]) zc:  torch.Size([37, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([1, 37, 3, 96, 96])) that is different to the input size (torch.Size([37, 3, 96, 96])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, batch : 75/93, loss = 0.005963\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 1/10, batch : 76/93, loss = 0.012251\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 1/10, batch : 77/93, loss = 0.006480\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 1/10, batch : 78/93, loss = 0.004360\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 1/10, batch : 79/93, loss = 0.008661\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n",
      "epoch : 1/10, batch : 80/93, loss = 0.005735\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 1/10, batch : 81/93, loss = 0.012781\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 1/10, batch : 82/93, loss = 0.008984\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 1/10, batch : 83/93, loss = 0.006922\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 1/10, batch : 84/93, loss = 0.004125\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 1/10, batch : 85/93, loss = 0.004236\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 1/10, batch : 86/93, loss = 0.009779\n",
      "input_vec.shape:  torch.Size([1, 44, 16])\n",
      "zm:  torch.Size([44, 2]) zc:  torch.Size([44, 2])\n",
      "epoch : 1/10, batch : 87/93, loss = 0.004918\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n",
      "epoch : 1/10, batch : 88/93, loss = 0.012516\n",
      "input_vec.shape:  torch.Size([1, 64, 16])\n",
      "zm:  torch.Size([64, 2]) zc:  torch.Size([64, 2])\n",
      "epoch : 1/10, batch : 89/93, loss = 0.005684\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 1/10, batch : 90/93, loss = 0.004466\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 1/10, batch : 91/93, loss = 0.004663\n",
      "input_vec.shape:  torch.Size([1, 38, 16])\n",
      "zm:  torch.Size([38, 2]) zc:  torch.Size([38, 2])\n",
      "epoch : 1/10, batch : 92/93, loss = 0.006163\n",
      "epoch : 1/10, loss = 0.0128\n",
      "input_vec.shape:  torch.Size([1, 73, 16])\n",
      "zm:  torch.Size([73, 2]) zc:  torch.Size([73, 2])\n",
      "epoch : 2/10, batch : 0/93, loss = 0.012136\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 2/10, batch : 1/93, loss = 0.004397\n",
      "input_vec.shape:  torch.Size([1, 44, 16])\n",
      "zm:  torch.Size([44, 2]) zc:  torch.Size([44, 2])\n",
      "epoch : 2/10, batch : 2/93, loss = 0.004524\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 2/10, batch : 3/93, loss = 0.003605\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 2/10, batch : 4/93, loss = 0.004292\n",
      "input_vec.shape:  torch.Size([1, 64, 16])\n",
      "zm:  torch.Size([64, 2]) zc:  torch.Size([64, 2])\n",
      "epoch : 2/10, batch : 5/93, loss = 0.005350\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 2/10, batch : 6/93, loss = 0.005062\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 2/10, batch : 7/93, loss = 0.004591\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 2/10, batch : 8/93, loss = 0.004059\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n",
      "epoch : 2/10, batch : 9/93, loss = 0.003876\n",
      "input_vec.shape:  torch.Size([1, 36, 16])\n",
      "zm:  torch.Size([36, 2]) zc:  torch.Size([36, 2])\n",
      "epoch : 2/10, batch : 10/93, loss = 0.006650\n",
      "input_vec.shape:  torch.Size([1, 47, 16])\n",
      "zm:  torch.Size([47, 2]) zc:  torch.Size([47, 2])\n",
      "epoch : 2/10, batch : 11/93, loss = 0.005842\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 2/10, batch : 12/93, loss = 0.004940\n",
      "input_vec.shape:  torch.Size([1, 65, 16])\n",
      "zm:  torch.Size([65, 2]) zc:  torch.Size([65, 2])\n",
      "epoch : 2/10, batch : 13/93, loss = 0.005052\n",
      "input_vec.shape:  torch.Size([1, 38, 16])\n",
      "zm:  torch.Size([38, 2]) zc:  torch.Size([38, 2])\n",
      "epoch : 2/10, batch : 14/93, loss = 0.005779\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 2/10, batch : 15/93, loss = 0.003872\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 2/10, batch : 16/93, loss = 0.005742\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 2/10, batch : 17/93, loss = 0.008471\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 2/10, batch : 18/93, loss = 0.009943\n",
      "input_vec.shape:  torch.Size([1, 46, 16])\n",
      "zm:  torch.Size([46, 2]) zc:  torch.Size([46, 2])\n",
      "epoch : 2/10, batch : 19/93, loss = 0.003059\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 2/10, batch : 20/93, loss = 0.004539\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 2/10, batch : 21/93, loss = 0.003084\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 2/10, batch : 22/93, loss = 0.004950\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 2/10, batch : 23/93, loss = 0.003488\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 2/10, batch : 24/93, loss = 0.006236\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 2/10, batch : 25/93, loss = 0.008010\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 2/10, batch : 26/93, loss = 0.005725\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 2/10, batch : 27/93, loss = 0.005003\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 2/10, batch : 28/93, loss = 0.004160\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n",
      "epoch : 2/10, batch : 29/93, loss = 0.004480\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 2/10, batch : 30/93, loss = 0.011893\n",
      "input_vec.shape:  torch.Size([1, 64, 16])\n",
      "zm:  torch.Size([64, 2]) zc:  torch.Size([64, 2])\n",
      "epoch : 2/10, batch : 31/93, loss = 0.004358\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n",
      "epoch : 2/10, batch : 32/93, loss = 0.008873\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 2/10, batch : 33/93, loss = 0.003027\n",
      "input_vec.shape:  torch.Size([1, 49, 16])\n",
      "zm:  torch.Size([49, 2]) zc:  torch.Size([49, 2])\n",
      "epoch : 2/10, batch : 34/93, loss = 0.008579\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n",
      "epoch : 2/10, batch : 35/93, loss = 0.005722\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 2/10, batch : 36/93, loss = 0.006303\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 2/10, batch : 37/93, loss = 0.003402\n",
      "input_vec.shape:  torch.Size([1, 73, 16])\n",
      "zm:  torch.Size([73, 2]) zc:  torch.Size([73, 2])\n",
      "epoch : 2/10, batch : 38/93, loss = 0.014353\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 2/10, batch : 39/93, loss = 0.006059\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 2/10, batch : 40/93, loss = 0.008329\n",
      "input_vec.shape:  torch.Size([1, 79, 16])\n",
      "zm:  torch.Size([79, 2]) zc:  torch.Size([79, 2])\n",
      "epoch : 2/10, batch : 41/93, loss = 0.005607\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2/10, batch : 42/93, loss = 0.009010\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 2/10, batch : 43/93, loss = 0.006455\n",
      "input_vec.shape:  torch.Size([1, 50, 16])\n",
      "zm:  torch.Size([50, 2]) zc:  torch.Size([50, 2])\n",
      "epoch : 2/10, batch : 44/93, loss = 0.005792\n",
      "input_vec.shape:  torch.Size([1, 31, 16])\n",
      "zm:  torch.Size([31, 2]) zc:  torch.Size([31, 2])\n",
      "epoch : 2/10, batch : 45/93, loss = 0.011661\n",
      "input_vec.shape:  torch.Size([1, 70, 16])\n",
      "zm:  torch.Size([70, 2]) zc:  torch.Size([70, 2])\n",
      "epoch : 2/10, batch : 46/93, loss = 0.003552\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n",
      "epoch : 2/10, batch : 47/93, loss = 0.005535\n",
      "input_vec.shape:  torch.Size([1, 78, 16])\n",
      "zm:  torch.Size([78, 2]) zc:  torch.Size([78, 2])\n",
      "epoch : 2/10, batch : 48/93, loss = 0.008981\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 2/10, batch : 49/93, loss = 0.005521\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 2/10, batch : 50/93, loss = 0.006241\n",
      "input_vec.shape:  torch.Size([1, 46, 16])\n",
      "zm:  torch.Size([46, 2]) zc:  torch.Size([46, 2])\n",
      "epoch : 2/10, batch : 51/93, loss = 0.007803\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 2/10, batch : 52/93, loss = 0.006454\n",
      "input_vec.shape:  torch.Size([1, 37, 16])\n",
      "zm:  torch.Size([37, 2]) zc:  torch.Size([37, 2])\n",
      "epoch : 2/10, batch : 53/93, loss = 0.005132\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 2/10, batch : 54/93, loss = 0.002854\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 2/10, batch : 55/93, loss = 0.003978\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 2/10, batch : 56/93, loss = 0.003931\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 2/10, batch : 57/93, loss = 0.009085\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 2/10, batch : 58/93, loss = 0.013209\n",
      "input_vec.shape:  torch.Size([1, 68, 16])\n",
      "zm:  torch.Size([68, 2]) zc:  torch.Size([68, 2])\n",
      "epoch : 2/10, batch : 59/93, loss = 0.004217\n",
      "input_vec.shape:  torch.Size([1, 38, 16])\n",
      "zm:  torch.Size([38, 2]) zc:  torch.Size([38, 2])\n",
      "epoch : 2/10, batch : 60/93, loss = 0.006155\n",
      "input_vec.shape:  torch.Size([1, 59, 16])\n",
      "zm:  torch.Size([59, 2]) zc:  torch.Size([59, 2])\n",
      "epoch : 2/10, batch : 61/93, loss = 0.006374\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 2/10, batch : 62/93, loss = 0.004254\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 2/10, batch : 63/93, loss = 0.006783\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 2/10, batch : 64/93, loss = 0.004907\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 2/10, batch : 65/93, loss = 0.003995\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 2/10, batch : 66/93, loss = 0.011442\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 2/10, batch : 67/93, loss = 0.005820\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 2/10, batch : 68/93, loss = 0.006418\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 2/10, batch : 69/93, loss = 0.004417\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 2/10, batch : 70/93, loss = 0.006948\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 2/10, batch : 71/93, loss = 0.008972\n",
      "input_vec.shape:  torch.Size([1, 28, 16])\n",
      "zm:  torch.Size([28, 2]) zc:  torch.Size([28, 2])\n",
      "epoch : 2/10, batch : 72/93, loss = 0.013578\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 2/10, batch : 73/93, loss = 0.012676\n",
      "input_vec.shape:  torch.Size([1, 49, 16])\n",
      "zm:  torch.Size([49, 2]) zc:  torch.Size([49, 2])\n",
      "epoch : 2/10, batch : 74/93, loss = 0.005135\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 2/10, batch : 75/93, loss = 0.007872\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 2/10, batch : 76/93, loss = 0.007331\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n",
      "epoch : 2/10, batch : 77/93, loss = 0.010369\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 2/10, batch : 78/93, loss = 0.004994\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 2/10, batch : 79/93, loss = 0.005894\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 2/10, batch : 80/93, loss = 0.006502\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 2/10, batch : 81/93, loss = 0.003499\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 2/10, batch : 82/93, loss = 0.004590\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 2/10, batch : 83/93, loss = 0.004195\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n",
      "epoch : 2/10, batch : 84/93, loss = 0.004586\n",
      "input_vec.shape:  torch.Size([1, 36, 16])\n",
      "zm:  torch.Size([36, 2]) zc:  torch.Size([36, 2])\n",
      "epoch : 2/10, batch : 85/93, loss = 0.005601\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 2/10, batch : 86/93, loss = 0.004845\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 2/10, batch : 87/93, loss = 0.013461\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 2/10, batch : 88/93, loss = 0.012459\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 2/10, batch : 89/93, loss = 0.011407\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 2/10, batch : 90/93, loss = 0.010079\n",
      "input_vec.shape:  torch.Size([1, 44, 16])\n",
      "zm:  torch.Size([44, 2]) zc:  torch.Size([44, 2])\n",
      "epoch : 2/10, batch : 91/93, loss = 0.005125\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 2/10, batch : 92/93, loss = 0.004287\n",
      "epoch : 2/10, loss = 0.0065\n",
      "input_vec.shape:  torch.Size([1, 70, 16])\n",
      "zm:  torch.Size([70, 2]) zc:  torch.Size([70, 2])\n",
      "epoch : 3/10, batch : 0/93, loss = 0.004227\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 3/10, batch : 1/93, loss = 0.004628\n",
      "input_vec.shape:  torch.Size([1, 55, 16])\n",
      "zm:  torch.Size([55, 2]) zc:  torch.Size([55, 2])\n",
      "epoch : 3/10, batch : 2/93, loss = 0.003663\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 3/10, batch : 3/93, loss = 0.009850\n",
      "input_vec.shape:  torch.Size([1, 28, 16])\n",
      "zm:  torch.Size([28, 2]) zc:  torch.Size([28, 2])\n",
      "epoch : 3/10, batch : 4/93, loss = 0.012350\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 3/10, batch : 5/93, loss = 0.006728\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 3/10, batch : 6/93, loss = 0.007462\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 3/10, batch : 7/93, loss = 0.003132\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 3/10, batch : 8/93, loss = 0.005302\n",
      "input_vec.shape:  torch.Size([1, 73, 16])\n",
      "zm:  torch.Size([73, 2]) zc:  torch.Size([73, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3/10, batch : 9/93, loss = 0.012222\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 3/10, batch : 10/93, loss = 0.003771\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n",
      "epoch : 3/10, batch : 11/93, loss = 0.004710\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 3/10, batch : 12/93, loss = 0.005590\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 3/10, batch : 13/93, loss = 0.009970\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n",
      "epoch : 3/10, batch : 14/93, loss = 0.004371\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 3/10, batch : 15/93, loss = 0.004734\n",
      "input_vec.shape:  torch.Size([1, 48, 16])\n",
      "zm:  torch.Size([48, 2]) zc:  torch.Size([48, 2])\n",
      "epoch : 3/10, batch : 16/93, loss = 0.003769\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 3/10, batch : 17/93, loss = 0.003731\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 3/10, batch : 18/93, loss = 0.008580\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 3/10, batch : 19/93, loss = 0.008686\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 3/10, batch : 20/93, loss = 0.006386\n",
      "input_vec.shape:  torch.Size([1, 51, 16])\n",
      "zm:  torch.Size([51, 2]) zc:  torch.Size([51, 2])\n",
      "epoch : 3/10, batch : 21/93, loss = 0.010968\n",
      "input_vec.shape:  torch.Size([1, 36, 16])\n",
      "zm:  torch.Size([36, 2]) zc:  torch.Size([36, 2])\n",
      "epoch : 3/10, batch : 22/93, loss = 0.005836\n",
      "input_vec.shape:  torch.Size([1, 47, 16])\n",
      "zm:  torch.Size([47, 2]) zc:  torch.Size([47, 2])\n",
      "epoch : 3/10, batch : 23/93, loss = 0.005412\n",
      "input_vec.shape:  torch.Size([1, 40, 16])\n",
      "zm:  torch.Size([40, 2]) zc:  torch.Size([40, 2])\n",
      "epoch : 3/10, batch : 24/93, loss = 0.004575\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 3/10, batch : 25/93, loss = 0.003682\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 3/10, batch : 26/93, loss = 0.005009\n",
      "input_vec.shape:  torch.Size([1, 39, 16])\n",
      "zm:  torch.Size([39, 2]) zc:  torch.Size([39, 2])\n",
      "epoch : 3/10, batch : 27/93, loss = 0.003586\n",
      "input_vec.shape:  torch.Size([1, 68, 16])\n",
      "zm:  torch.Size([68, 2]) zc:  torch.Size([68, 2])\n",
      "epoch : 3/10, batch : 28/93, loss = 0.003195\n",
      "input_vec.shape:  torch.Size([1, 52, 16])\n",
      "zm:  torch.Size([52, 2]) zc:  torch.Size([52, 2])\n",
      "epoch : 3/10, batch : 29/93, loss = 0.010044\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 3/10, batch : 30/93, loss = 0.003969\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 3/10, batch : 31/93, loss = 0.003890\n",
      "input_vec.shape:  torch.Size([1, 44, 16])\n",
      "zm:  torch.Size([44, 2]) zc:  torch.Size([44, 2])\n",
      "epoch : 3/10, batch : 32/93, loss = 0.004603\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 3/10, batch : 33/93, loss = 0.014305\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 3/10, batch : 34/93, loss = 0.002872\n",
      "input_vec.shape:  torch.Size([1, 43, 16])\n",
      "zm:  torch.Size([43, 2]) zc:  torch.Size([43, 2])\n",
      "epoch : 3/10, batch : 35/93, loss = 0.004558\n",
      "input_vec.shape:  torch.Size([1, 31, 16])\n",
      "zm:  torch.Size([31, 2]) zc:  torch.Size([31, 2])\n",
      "epoch : 3/10, batch : 36/93, loss = 0.012337\n",
      "input_vec.shape:  torch.Size([1, 45, 16])\n",
      "zm:  torch.Size([45, 2]) zc:  torch.Size([45, 2])\n",
      "epoch : 3/10, batch : 37/93, loss = 0.009784\n",
      "input_vec.shape:  torch.Size([1, 78, 16])\n",
      "zm:  torch.Size([78, 2]) zc:  torch.Size([78, 2])\n",
      "epoch : 3/10, batch : 38/93, loss = 0.008566\n",
      "input_vec.shape:  torch.Size([1, 63, 16])\n",
      "zm:  torch.Size([63, 2]) zc:  torch.Size([63, 2])\n",
      "epoch : 3/10, batch : 39/93, loss = 0.004172\n",
      "input_vec.shape:  torch.Size([1, 64, 16])\n",
      "zm:  torch.Size([64, 2]) zc:  torch.Size([64, 2])\n",
      "epoch : 3/10, batch : 40/93, loss = 0.004239\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 3/10, batch : 41/93, loss = 0.004249\n",
      "input_vec.shape:  torch.Size([1, 62, 16])\n",
      "zm:  torch.Size([62, 2]) zc:  torch.Size([62, 2])\n",
      "epoch : 3/10, batch : 42/93, loss = 0.006806\n",
      "input_vec.shape:  torch.Size([1, 37, 16])\n",
      "zm:  torch.Size([37, 2]) zc:  torch.Size([37, 2])\n",
      "epoch : 3/10, batch : 43/93, loss = 0.005129\n",
      "input_vec.shape:  torch.Size([1, 49, 16])\n",
      "zm:  torch.Size([49, 2]) zc:  torch.Size([49, 2])\n",
      "epoch : 3/10, batch : 44/93, loss = 0.007818\n",
      "input_vec.shape:  torch.Size([1, 56, 16])\n",
      "zm:  torch.Size([56, 2]) zc:  torch.Size([56, 2])\n",
      "epoch : 3/10, batch : 45/93, loss = 0.006205\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 3/10, batch : 46/93, loss = 0.004095\n",
      "input_vec.shape:  torch.Size([1, 53, 16])\n",
      "zm:  torch.Size([53, 2]) zc:  torch.Size([53, 2])\n",
      "epoch : 3/10, batch : 47/93, loss = 0.004586\n",
      "input_vec.shape:  torch.Size([1, 41, 16])\n",
      "zm:  torch.Size([41, 2]) zc:  torch.Size([41, 2])\n",
      "epoch : 3/10, batch : 48/93, loss = 0.009089\n",
      "input_vec.shape:  torch.Size([1, 57, 16])\n",
      "zm:  torch.Size([57, 2]) zc:  torch.Size([57, 2])\n",
      "epoch : 3/10, batch : 49/93, loss = 0.003705\n",
      "input_vec.shape:  torch.Size([1, 46, 16])\n",
      "zm:  torch.Size([46, 2]) zc:  torch.Size([46, 2])\n",
      "epoch : 3/10, batch : 50/93, loss = 0.002636\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 3/10, batch : 51/93, loss = 0.002349\n",
      "input_vec.shape:  torch.Size([1, 38, 16])\n",
      "zm:  torch.Size([38, 2]) zc:  torch.Size([38, 2])\n",
      "epoch : 3/10, batch : 52/93, loss = 0.005050\n",
      "input_vec.shape:  torch.Size([1, 61, 16])\n",
      "zm:  torch.Size([61, 2]) zc:  torch.Size([61, 2])\n",
      "epoch : 3/10, batch : 53/93, loss = 0.005333\n",
      "input_vec.shape:  torch.Size([1, 42, 16])\n",
      "zm:  torch.Size([42, 2]) zc:  torch.Size([42, 2])\n",
      "epoch : 3/10, batch : 54/93, loss = 0.003885\n",
      "input_vec.shape:  torch.Size([1, 54, 16])\n",
      "zm:  torch.Size([54, 2]) zc:  torch.Size([54, 2])\n",
      "epoch : 3/10, batch : 55/93, loss = 0.003228\n",
      "input_vec.shape:  torch.Size([1, 67, 16])\n",
      "zm:  torch.Size([67, 2]) zc:  torch.Size([67, 2])\n",
      "epoch : 3/10, batch : 56/93, loss = 0.002839\n",
      "input_vec.shape:  torch.Size([1, 60, 16])\n",
      "zm:  torch.Size([60, 2]) zc:  torch.Size([60, 2])\n",
      "epoch : 3/10, batch : 57/93, loss = 0.004973\n",
      "input_vec.shape:  torch.Size([1, 72, 16])\n",
      "zm:  torch.Size([72, 2]) zc:  torch.Size([72, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-992cd2cd21fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mx_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_id, (batch_data, _) in enumerate(train_loader):\n",
    "        # print(torch.cuda.memory_allocated(device))\n",
    "        \n",
    "        # batch_data: 5D-Tensor (batch_size=1, video_len, channel, height, width)\n",
    "        x = batch_data.to(device) \n",
    "               \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # x_hat: (video_len, channel, height, width)\n",
    "        # zc: (video_len, dim_zc)        \n",
    "        x_hat = model(x) \n",
    "        \n",
    "        print(x_hat)\n",
    "\n",
    "        loss = criterion(x_hat, x)\n",
    "        loss.backward() # compute accumulated gradients\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "                \n",
    "        print(\"epoch : {}/{}, batch : {}/{}, loss = {:.6f}\".format(\n",
    "            epoch + 1, n_epochs, batch_id, int(len(train_dataset)/batch_size), loss.item()))   \n",
    "        del x_hat\n",
    "    print(\"epoch : {}/{}, loss = {:.4f}\".format(epoch + 1, n_epochs, train_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
