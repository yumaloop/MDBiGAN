{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from dataset import WeizmannHumanActionVideo\n",
    "from image_autoencoder import ImageAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trans_data = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\"\"\"\n",
    "\n",
    "trans_data = torchvision.transforms.ToTensor()\n",
    "trans_label = None\n",
    "\n",
    "dataset = WeizmannHumanActionVideo(trans_data=None, trans_label=trans_label, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  74\n",
      "test:  19\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", len(train_dataset))\n",
    "print(\"test: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 48, 3, 96, 96]) tensor([1])\n",
      "1 torch.Size([1, 64, 3, 96, 96]) tensor([1])\n",
      "2 torch.Size([1, 61, 3, 96, 96]) tensor([4])\n",
      "3 torch.Size([1, 65, 3, 96, 96]) tensor([4])\n",
      "4 torch.Size([1, 36, 3, 96, 96]) tensor([6])\n",
      "5 torch.Size([1, 56, 3, 96, 96]) tensor([7])\n",
      "6 torch.Size([1, 54, 3, 96, 96]) tensor([7])\n",
      "7 torch.Size([1, 54, 3, 96, 96]) tensor([9])\n",
      "8 torch.Size([1, 28, 3, 96, 96]) tensor([6])\n",
      "9 torch.Size([1, 88, 3, 96, 96]) tensor([3])\n",
      "10 torch.Size([1, 54, 3, 96, 96]) tensor([5])\n",
      "11 torch.Size([1, 39, 3, 96, 96]) tensor([1])\n",
      "12 torch.Size([1, 67, 3, 96, 96]) tensor([8])\n",
      "13 torch.Size([1, 62, 3, 96, 96]) tensor([5])\n",
      "14 torch.Size([1, 55, 3, 96, 96]) tensor([0])\n",
      "15 torch.Size([1, 146, 3, 96, 96]) tensor([0])\n",
      "16 torch.Size([1, 47, 3, 96, 96]) tensor([8])\n",
      "17 torch.Size([1, 114, 3, 96, 96]) tensor([2])\n",
      "18 torch.Size([1, 60, 3, 96, 96]) tensor([7])\n",
      "19 torch.Size([1, 48, 3, 96, 96]) tensor([7])\n",
      "20 torch.Size([1, 70, 3, 96, 96]) tensor([0])\n",
      "21 torch.Size([1, 82, 3, 96, 96]) tensor([9])\n",
      "22 torch.Size([1, 61, 3, 96, 96]) tensor([9])\n",
      "23 torch.Size([1, 52, 3, 96, 96]) tensor([7])\n",
      "24 torch.Size([1, 52, 3, 96, 96]) tensor([1])\n",
      "25 torch.Size([1, 79, 3, 96, 96]) tensor([2])\n",
      "26 torch.Size([1, 81, 3, 96, 96]) tensor([2])\n",
      "27 torch.Size([1, 68, 3, 96, 96]) tensor([3])\n",
      "28 torch.Size([1, 49, 3, 96, 96]) tensor([6])\n",
      "29 torch.Size([1, 72, 3, 96, 96]) tensor([8])\n",
      "30 torch.Size([1, 39, 3, 96, 96]) tensor([7])\n",
      "31 torch.Size([1, 48, 3, 96, 96]) tensor([5])\n",
      "32 torch.Size([1, 45, 3, 96, 96]) tensor([7])\n",
      "33 torch.Size([1, 37, 3, 96, 96]) tensor([7])\n",
      "34 torch.Size([1, 64, 3, 96, 96]) tensor([4])\n",
      "35 torch.Size([1, 45, 3, 96, 96]) tensor([5])\n",
      "36 torch.Size([1, 103, 3, 96, 96]) tensor([9])\n",
      "37 torch.Size([1, 59, 3, 96, 96]) tensor([2])\n",
      "38 torch.Size([1, 63, 3, 96, 96]) tensor([4])\n",
      "39 torch.Size([1, 41, 3, 96, 96]) tensor([6])\n",
      "40 torch.Size([1, 127, 3, 96, 96]) tensor([5])\n",
      "41 torch.Size([1, 56, 3, 96, 96]) tensor([6])\n",
      "42 torch.Size([1, 78, 3, 96, 96]) tensor([3])\n",
      "43 torch.Size([1, 51, 3, 96, 96]) tensor([2])\n",
      "44 torch.Size([1, 93, 3, 96, 96]) tensor([4])\n",
      "45 torch.Size([1, 60, 3, 96, 96]) tensor([9])\n",
      "46 torch.Size([1, 31, 3, 96, 96]) tensor([6])\n",
      "47 torch.Size([1, 45, 3, 96, 96]) tensor([8])\n",
      "48 torch.Size([1, 61, 3, 96, 96]) tensor([4])\n",
      "49 torch.Size([1, 85, 3, 96, 96]) tensor([4])\n",
      "50 torch.Size([1, 84, 3, 96, 96]) tensor([3])\n",
      "51 torch.Size([1, 40, 3, 96, 96]) tensor([8])\n",
      "52 torch.Size([1, 39, 3, 96, 96]) tensor([8])\n",
      "53 torch.Size([1, 55, 3, 96, 96]) tensor([9])\n",
      "54 torch.Size([1, 45, 3, 96, 96]) tensor([6])\n",
      "55 torch.Size([1, 38, 3, 96, 96]) tensor([7])\n",
      "56 torch.Size([1, 42, 3, 96, 96]) tensor([5])\n",
      "57 torch.Size([1, 54, 3, 96, 96]) tensor([0])\n",
      "58 torch.Size([1, 57, 3, 96, 96]) tensor([2])\n",
      "59 torch.Size([1, 105, 3, 96, 96]) tensor([0])\n",
      "60 torch.Size([1, 53, 3, 96, 96]) tensor([1])\n",
      "61 torch.Size([1, 103, 3, 96, 96]) tensor([0])\n",
      "62 torch.Size([1, 57, 3, 96, 96]) tensor([7])\n",
      "63 torch.Size([1, 49, 3, 96, 96]) tensor([5])\n",
      "64 torch.Size([1, 41, 3, 96, 96]) tensor([6])\n",
      "65 torch.Size([1, 73, 3, 96, 96]) tensor([3])\n",
      "66 torch.Size([1, 72, 3, 96, 96]) tensor([3])\n",
      "67 torch.Size([1, 67, 3, 96, 96]) tensor([8])\n",
      "68 torch.Size([1, 43, 3, 96, 96]) tensor([3])\n",
      "69 torch.Size([1, 38, 3, 96, 96]) tensor([8])\n",
      "70 torch.Size([1, 63, 3, 96, 96]) tensor([4])\n",
      "71 torch.Size([1, 67, 3, 96, 96]) tensor([2])\n",
      "72 torch.Size([1, 39, 3, 96, 96]) tensor([1])\n",
      "73 torch.Size([1, 46, 3, 96, 96]) tensor([1])\n"
     ]
    }
   ],
   "source": [
    "for i, (data, label) in enumerate(train_loader):\n",
    "    print(i,  data.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterative algorithm (SGD)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "\n",
    "model = ImageAutoEncoder(n_channel=3, dim_zm=2, dim_zc=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8673792\n",
      "14645760\n",
      "3518821888\n",
      "epoch : 1/10, batch : 0/74, loss = 0.757574\n",
      "34936832\n",
      "40908800\n",
      "3088010752\n",
      "epoch : 1/10, batch : 1/74, loss = 0.439633\n",
      "34936832\n",
      "40908800\n",
      "3411451392\n",
      "epoch : 1/10, batch : 2/74, loss = 0.377576\n",
      "34936832\n",
      "42346496\n",
      "4386195456\n",
      "epoch : 1/10, batch : 3/74, loss = 0.283066\n",
      "34937344\n",
      "40909312\n",
      "3024748032\n",
      "epoch : 1/10, batch : 4/74, loss = 0.244832\n",
      "34936832\n",
      "40908800\n",
      "3543955456\n",
      "epoch : 1/10, batch : 5/74, loss = 0.233834\n",
      "34936832\n",
      "38365184\n",
      "2048748544\n",
      "epoch : 1/10, batch : 6/74, loss = 0.227067\n",
      "34936832\n",
      "39249920\n",
      "2568700416\n",
      "epoch : 1/10, batch : 7/74, loss = 0.214250\n",
      "34936832\n",
      "42899456\n",
      "4710548480\n",
      "epoch : 1/10, batch : 8/74, loss = nan\n",
      "34937344\n",
      "40909312\n",
      "3477203968\n",
      "epoch : 1/10, batch : 9/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "3152310272\n",
      "epoch : 1/10, batch : 10/74, loss = nan\n",
      "34936832\n",
      "44226560\n",
      "5491292160\n",
      "epoch : 1/10, batch : 11/74, loss = nan\n",
      "34937344\n",
      "39139840\n",
      "2503007744\n",
      "epoch : 1/10, batch : 12/74, loss = nan\n",
      "34936832\n",
      "41682944\n",
      "3995145728\n",
      "epoch : 1/10, batch : 13/74, loss = nan\n",
      "34936832\n",
      "41461760\n",
      "3865304576\n",
      "epoch : 1/10, batch : 14/74, loss = nan\n",
      "34936832\n",
      "41019392\n",
      "3606535680\n",
      "epoch : 1/10, batch : 15/74, loss = nan\n",
      "34936832\n",
      "44668928\n",
      "5752508928\n",
      "epoch : 1/10, batch : 16/74, loss = nan\n",
      "34937344\n",
      "40909312\n",
      "2957985280\n",
      "epoch : 1/10, batch : 17/74, loss = nan\n",
      "34936832\n",
      "41240576\n",
      "3736621568\n",
      "epoch : 1/10, batch : 18/74, loss = nan\n",
      "34936832\n",
      "41793536\n",
      "4061059584\n",
      "epoch : 1/10, batch : 19/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "3541523456\n",
      "epoch : 1/10, batch : 20/74, loss = nan\n",
      "34936832\n",
      "42346496\n",
      "4385582080\n",
      "epoch : 1/10, batch : 21/74, loss = nan\n",
      "34937344\n",
      "41904640\n",
      "4125925888\n",
      "epoch : 1/10, batch : 22/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "3218145792\n",
      "epoch : 1/10, batch : 23/74, loss = nan\n",
      "34936832\n",
      "38033408\n",
      "1854391296\n",
      "epoch : 1/10, batch : 24/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "2957985280\n",
      "epoch : 1/10, batch : 25/74, loss = nan\n",
      "34936832\n",
      "46327808\n",
      "6725504512\n",
      "epoch : 1/10, batch : 26/74, loss = nan\n",
      "34937344\n",
      "40909312\n",
      "3154052608\n",
      "epoch : 1/10, batch : 27/74, loss = nan\n",
      "34936832\n",
      "42457088\n",
      "4451072000\n",
      "epoch : 1/10, batch : 28/74, loss = nan\n",
      "34937344\n",
      "43010560\n",
      "4775232000\n",
      "epoch : 1/10, batch : 29/74, loss = nan\n",
      "34937344\n",
      "39139840\n",
      "2503716864\n",
      "epoch : 1/10, batch : 30/74, loss = nan\n",
      "34936832\n",
      "41129984\n",
      "3670730752\n",
      "epoch : 1/10, batch : 31/74, loss = nan\n",
      "34936832\n",
      "41129984\n",
      "3670730752\n",
      "epoch : 1/10, batch : 32/74, loss = nan\n",
      "34936832\n",
      "39360512\n",
      "2634829312\n",
      "epoch : 1/10, batch : 33/74, loss = nan\n",
      "34936832\n",
      "43673600\n",
      "5164600320\n",
      "epoch : 1/10, batch : 34/74, loss = nan\n",
      "34937344\n",
      "41572864\n",
      "3932510720\n",
      "epoch : 1/10, batch : 35/74, loss = nan\n",
      "34936832\n",
      "41682944\n",
      "3998089728\n",
      "epoch : 1/10, batch : 36/74, loss = nan\n",
      "34936832\n",
      "38918144\n",
      "2373001728\n",
      "epoch : 1/10, batch : 37/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "3413362176\n",
      "epoch : 1/10, batch : 38/74, loss = nan\n",
      "34936832\n",
      "40908800\n",
      "3154052608\n",
      "epoch : 1/10, batch : 39/74, loss = nan\n",
      "34936832\n",
      "42125312\n",
      "4256295936\n",
      "epoch : 1/10, batch : 40/74, loss = nan\n",
      "34937344\n",
      "39029248\n",
      "2438516736\n",
      "epoch : 1/10, batch : 41/74, loss = nan\n",
      "34936832\n",
      "44005376\n",
      "5358937088\n",
      "epoch : 1/10, batch : 42/74, loss = nan\n",
      "34937344\n",
      "48982528\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 7.93 GiB total capacity; 6.88 GiB already allocated; 161.06 MiB free; 195.52 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7f42b5084bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x_hat: (video_len, channel, height, width),  zc: (video_len, dim_zc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/mdbigan/image_autoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m         \u001b[0mzm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_zm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zm: (batch_size, dim_zm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mzc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_zc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zc: (batch_size, dim_zc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mzm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# z: (batch_size, dim_z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# z: (batch_size, dim_z, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 7.93 GiB total capacity; 6.88 GiB already allocated; 161.06 MiB free; 195.52 MiB cached)"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_id, (batch_data, _) in enumerate(train_loader):\n",
    "        print(torch.cuda.memory_allocated(device))\n",
    "        \n",
    "        # x: 4D (video_len, channel, height, width)\n",
    "        x = torch.squeeze(batch_data, dim=0).to(device) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        print(torch.cuda.memory_allocated(device))\n",
    "        x_hat, zc = model(x) # x_hat: (video_len, channel, height, width),  zc: (video_len, dim_zc)        \n",
    "        print(torch.cuda.memory_allocated(device))\n",
    "\n",
    "        # loss = criterion(x_hat, x) + torch.norm(zc.std(dim=0), 2)\n",
    "        loss = criterion(x_hat, x) + torch.norm(zc.std(dim=0), 2)\n",
    "        loss.backward() # compute accumulated gradients\n",
    "        \n",
    "        # train_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "                \n",
    "        print(\"epoch : {}/{}, batch : {}/{}, loss = {:.6f}\".format(\n",
    "            epoch + 1, n_epochs, batch_id, int(len(train_dataset)/batch_size), loss.item()))\n",
    "        \n",
    "        del loss\n",
    "        del x_hat\n",
    "        del x        \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.4f}\".format(epoch + 1, n_epochs, train_loss / len(train_loader)))\n",
    "    # print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
