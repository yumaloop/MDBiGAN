{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from dataset import WeizmannHumanActionVideo\n",
    "from image_autoencoder import ImageAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trans_data = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\"\"\"\n",
    "\n",
    "trans_data = torchvision.transforms.ToTensor()\n",
    "trans_label = None\n",
    "\n",
    "dataset = WeizmannHumanActionVideo(trans_data=None, trans_label=trans_label, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  93\n",
      "test:  0\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "train_size = int(1.0 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print(\"train: \", len(train_dataset))\n",
    "print(\"test: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "n_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_loader = torch.utils.data.DataLoader(test_dataset, \\n                                           batch_size=batch_size, \\n                                           shuffle=True, \\n                                           num_workers=1)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=4)\n",
    "\n",
    "\"\"\"\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"trained_models/image_autoencoder.pth\"\n",
    "model = ImageAutoEncoder(n_channel=3, dim_zm=2, dim_zc=2).to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageAutoEncoder(\n",
       "  (encoder_zm): Sequential(\n",
       "    (0): Conv2d(3, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (13): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (15): Flatten()\n",
       "    (16): Linear(in_features=6561, out_features=2, bias=True)\n",
       "    (17): Tanh()\n",
       "  )\n",
       "  (encoder_zc): Sequential(\n",
       "    (0): Conv2d(3, 256, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Conv2d(256, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Conv2d(128, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (13): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (15): Flatten()\n",
       "    (16): Linear(in_features=6561, out_features=2, bias=True)\n",
       "    (17): Tanh()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(4, 256, kernel_size=(6, 6), stride=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (13): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "torch.Size([67, 3, 96, 96]) torch.Size([67, 3, 96, 96]) torch.Size([67, 2])\n"
     ]
    }
   ],
   "source": [
    "epoch=0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (batch_data, _) in enumerate(train_loader):\n",
    "     \n",
    "        # x: 4D-Tensor (video_len, channel, height, width)\n",
    "        x = torch.squeeze(batch_data, dim=0).to(device)\n",
    "        x_hat_z, x_hat_zc, zc = model(x)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            n = x.size(0)\n",
    "            print(n)\n",
    "            print(x.shape, x_hat_z.shape, x_hat_zc.shape)\n",
    "            # comparison = torch.cat([x[:n], x_hat_z.view(x.shape[0], 3, 96, 96)[:n], x_hat_zc.view(x.shape[0], 3, 96, 96)[:n]])\n",
    "            # comparison = torch.cat([x[:n], x_hat_z[:n], x_hat_zc[:n]])\n",
    "            comparison = torch.cat([x[:n], x_hat_z[:n]])\n",
    "            save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
